ADualAugmentedTwo-towerModelforOnlineLarge-scale 
Recommendation 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 
Meituan 
Beijing,China 
{yuyantao,wangweipeng02,fengzhoutian,xuedaiyue}@meituan.com 


ABSTRACT 


Manymodernrecommendersystemshaveaverylargecorpus,and 
acommonindustrialrecipeforhandlinglarge-scaleretrievalis 
tolearnqueryanditemrepresentationsfromtheircontentfeatureswiththetwo-
towermodel.However,themodelsuffersfrom 
lackofinformationinteractionbetweenthetwotowers.Besides, 
imbalancedcategorydataalsohindersthemodelperformance. 
Inthispaper,weproposeanovelmodelnamedDualAugmented 
Two-towerModel(DAT),whichintegratesanovelAdaptive-Mimic 
Mechanism(AMM)andaCategoryAlignmentLoss(CAL).Our 
AMMcustomizesanaugmentedvectorforeachqueryanditemto 
mitigatethelackofinformationinteraction.Moreover,ourCAL 
canfurtherimproveperformancebyaligningitemrepresentation 
ofunevencategories.Offlineexperimentsonlarge-scaledatasets 
areconductedtoshowthesuperiorperformanceofDAT.Moreover,
onlineA/BtestingsconfirmthatDATcanleadtoimproved 
recommendationqualityforindustrialapplications. 


CCSCONCEPTS 
•Informationsystems→Recommendersystems;Information 
retrieval. 


KEYWORDS 


RecommenderSystems,InformationRetrieval,NeuralNetworks 


ACMReferenceFormat: 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue.2021.ADual 
AugmentedTwo-towerModelforOnlineLarge-scaleRecommendation. 
InProceedingsofDLP-KDD2021.ACM,NewYork,NY,USA,4pages.https: 
//doi.org/10.1145/1122445.1122456 


1 
INTRODUCTION 


Recommendersystemsareindispensableinfilteringoutitemsthat 
usersareinterestedinfromhugeamountsofitems.Oneofthe 
mostcrucialchallengesinlarge-scalerecommendationistoscore 
millionsorbillionsofitemsinreal-timeaccurately.Acommon 
practiceistodesigntherecommenderasatwo-phasearchitecture 
wherearetrievalmodelfirstretrievesasmallfractionofrelated 
itemsgivenuser’squeryfromalargecorpus,andarankingmodel 


Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor 
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed 
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation 
onthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACM 
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish, 
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora 
fee.Requestpermissionsfrompermissions@acm.org. 


DLP-KDD2021,August15,2021,Singapore 


©2021AssociationforComputingMachinery. 
ACMISBN978-1-4503-XXXX-X/18/06...$15.00 
https://doi.org/10.1145/1122445.1122456 


rankstheretrieveditemsbasedonclicksoruser-ratings[2].Obviously,
thequalityofcandidatesretrievedintheretrievalstage 
playsacriticalroleinthewholesystem.Inthiswork,wefocuson 
theretrievalproblemwithanaimtoimprovetheretrievalsystem’s 
performanceforpersonalizedrecommendationwithmillionsof 
queriesanditems. 


Ascalableretrievalmodelusuallylearnsqueryanditemrepresentationsfirstandthenusesacosinesimilaritybetweenthequery 
anditemrepresentationstoobtainrecommendationstailoredfor 
thequery.However,inindustrial-scaleapplications,thecorpusof 
itemscanbeenormouslylargeandthetrainingdatacollectedfrom 
users’feedbackislikelytobeverysparseformostqueriesand 
items,whichmayleadtoinaccuratemodelpredictionsforlong-tail 
usersanditems.Totackletheabovechallenges,thetwo-tower 
model[4],withtowersreferringtoencodersbasedondeepneural 
networks(DNNs),areusuallyapplied.Despitegreatpromise,there 
arestillsomeproblemsintwo-towermodel.Astheitemrepresentationoftheitemtowermustbepre-
computedseparatelyforonline 
retrievalservice,theforwardcomputationoftheitemtowermust 
beindependentwiththequerytower,andsothemodellacksinformationinteractionbetweenthetwotowers,
whichmayinevitably 
hinderthemodel’sperformance.Inreal-worldapplications,the 
inputofonetowerhasapositiveinteractionwiththeinputofthe 
otherforeachclick.Forexample,supposethatitem𝐴 
isclicked 
inqueries{𝐵,𝐶, 
𝐷}.Apparently,theinputsforthequerytower 
are{𝐵,𝐶, 
𝐷},whichinteractwiththeinput𝐴 
oftheitemtower. 
Consequently,theinformationcontainedinthequerytowercan 
beleveragedtoaugmenttheitemrepresentationoftheitemtower, 
andviceversa.Furthermore,thecategoriesofitemsarediverse(e.g., 
food,hotels,movies,etc.)andtheamountofitemsineachcategory 
isimbalancedseverely.Thustheitemsinanindividualcategory 
mayaccountforthemajority.Consequently,modelperformsmuch 
worseonthecategorieswithrelativelysmalleramountofitems. 


Inthispaper,totackletheaboveissues,wepresentanovel 
retrievalmodelforlarge-scalerecommendationnamedDualAugmentedTwo-
towerModel(DAT).Specifically,wedesignanAdaptiveMimicMechanismtocustomizeanaugmentedvectorforeachquery 
anditemastheircontentfeatures.Theaugmentedvectorisupdated 
accordingtotheoutputrepresentationvectoroftheothertowerfor 
eachsamplewithpositivelabels.Inthisway,theaugmentedvector 
astheinputfeatureofonetowercarriesvaluableinformationofthe 
othertower,whichimplicitlymodelstheinformationinteraction 
betweenthetwotowers.AndwealsointroduceaCategoryAlignmentLossinthetrainingphasetoaligntherepresentationforitems 
fromdifferentcategories.Comprehensiveexperimentsshowthat 
ourDATfeatureshavetwomajoradvantages:i).itprovidesdeeper 
insightsintotheinformationinteractionoftwo-towermodelsin 



DLP-KDD2021,August15,2021,Singapore 
YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 



Figure1:ThenetworkarchitectureofourproposedDualAugmentedTwo-towerModel 


theretrievaltask;ii).itproducesbetteritemrepresentationswhen 
thecategorydistributionisextremelyimbalanced. 


2 
MODELARCHITECTURE 


2.1 
ProblemStatement 
Weconsiderarecommendationsystemwithaqueryset{u𝑖 
}𝑁 


𝑖=1

 
𝑀 


andanitemset 
v𝑗 
=1,where𝑁 
isthenumberofusersand𝑀 
is

𝑗 
thenumberofitems.Hereu𝑖 
,v𝑗 
aretheconcatenationsofvarious 
features(e.g.,IDsandcontentfeatures),whichcanbeveryhighdimensionalduetothesparsity.
Thequery-itemfeedbackcanbe 
representedbyamatrix𝑅 
∈R𝑁 
×𝑀 
,where𝑅𝑖 
𝑗 
= 
1ifquery𝑖 
gives 
apositivefeedbackonitem𝑗,and𝑅𝑖 
𝑗 
= 
0otherwise.Ourobjective 
istoefficientlyselectpossiblythousandsofcandidateitemsfrom 
theentireitemcorpusgivenacertainquery. 


2.2 
DualAugmentedTwo-towerModel 
TheframeworkofourproposedmodelisillustratedinFigure1. 
TheDATmodelusesanaugmentedvectora𝑢 
(a𝑣)tocapturethe 
informationfromtheothertower,andregardsthevectorasthe 
inputfeatureofonetower.Additionally,theCategoryAlignment 
Losstransferstheknowledgelearnedinthecategorywiththe 
largestamountofdatatoothercategories 


2.2.1 
EmbeddingLayer.Similartotwo-towermodels,eachfeature 
f𝑖 
∈ 
R 
(e.g.,anitemID)inu𝑖 
andv𝑗 
goesthroughanembedding 
R𝐾 


layerandismappedtoalow-dimensionaldensevectore𝑖 
∈ 
, 
where𝐾 
istheembeddingdimension.Specifically,wedefinean 
embeddingmatrixE∈R𝐾×𝐷 
whereEistobelearnedand𝐷 
isthe 
numberofuniquefeatures,andtheembeddingvectore𝑖 
isthe𝑖th 
columnoftheembeddingmatrixE. 


2.2.2 
DualAugmentedlayer.Foracertainqueryandcandidate 
item,wecreatetwocorrespondingaugmentedvectorsa𝑢 
anda𝑣 
by 
theirIDs,andconcatenatethemwithfeatureembeddingvectorsto 
obtaintheaugmentedinputvectorsz𝑢 
,z𝑣 
ofthetwotowers.For 
example,ifquery𝑢 
hasfeatures“uid=253,city=SH,gender=male,...” 
anditem𝑣 
hasfeatures“iid=149,price=10,class=cate,...”,wehave: 
z𝑢 
= 
[e253∥e𝑠ℎ 
∥e𝑚𝑎𝑙𝑒 
∥...∥a𝑢 
] 


z𝑣 
= 
[e149 
e𝑝10 
e𝑐𝑎𝑡𝑒 
∥...∥a𝑣 
] 


where|| 
isthevectorconcatenationoperation.Theaugmented 
inputvectorsz𝑢 
andz𝑣 
notonlycontaininformationaboutthecurrentqueryanditem,
butalsocontaininformationabouthistorical 
positiveinteractionsthrougha𝑢 
anda𝑣. 


Next,wefeedz𝑢 
andz𝑣 
intothetwotowers,whicharecomposed 
offullyconnectedlayerswiththeReLUactivationfunction,inorder 
toachievetheinformationinteractionbetweenthetwotowersbya𝑢 
anda𝑣 
(augmentedvectors).Next,theoutputofthefullyconnected 
layersgoesthroughanL2normalizationlayertogetaugmented 
representationsofqueryp𝑢 
anditemp𝑣.Formally,thedefinition 
ofthetwostepsisasfollows: 


h1= 
𝑅𝑒𝐿𝑈 
(W1z+b1),... 
h𝐿 
= 
𝑅𝑒𝐿𝑈 
(W𝑙 
h𝐿−1+b𝑙 
), 
(1) 
p= 
𝐿2𝑁𝑜𝑟𝑚 
(h𝐿 
) 


wherezdenotesz𝑢 
andz𝑣,pdenotesp𝑢 
andp𝑣 
;W𝑙 
andb𝑙 
arethe 
weightmatrixandbiasvectorforthe𝑙 
thlayer,respectively;p𝑢 
andp𝑣 
,theoutputvectorsoftheL2normalizationlayer,represent 
thequeryembeddinganditemembedding,respectively.Thetwo 
towershavethesamestructurebutdifferentparameters. 


Furthermore,toestimatetheaugmentedvectorsa𝑢 
anda𝑣,we 
designanAdaptive-MimicMechanism(AMM),whichintegrates 
amimiclossandastopgradientstrategy.Themimiclossaimsto 
usetheaugmentedvectortofitallpositiveinteractionsintheother 
towerbelongingtothecorrespondingqueryoritem.Wedefine 
mimiclossasthemeansquareerrorbetweentheaugmentedvector 
andquery/itemembeddingp𝑢 
,p𝑣 
foreachsampleofwhichlabel 
equalsto1: 


Õ

1 


𝑙𝑜𝑠𝑠𝑢 
= 
[𝑦a𝑢 
+(1−𝑦)p𝑣 
−p𝑣]2 


𝑇 


(𝑢,𝑣,𝑦)∈T

Õ 
(2)

1 


𝑙𝑜𝑠𝑠𝑣 
= 
[𝑦a𝑣 
+(1−𝑦)p𝑢 
−p𝑢 
]2 


𝑇 


(𝑢,𝑣,𝑦)∈T 


where𝑇 
isthenumberofquery-itempairsinthetrainingdatasetT, 
and𝑦 
∈{0, 
1}isthelabel.Wediscussthelabelingprocessinthenext 
sub-section.Ascanbeseen,ifthelabel𝑦 
= 
1,a𝑣 
anda𝑢 
approach 
thequeryembeddingp𝑢 
anditemembeddingp𝑣;ifthelabel𝑦 
= 
0, 



ADualAugmentedTwo-towerModelforOnlineLarge-scaleRecommendation 


thelossisisequalto0.AsshowninFigure1,theaugmentedvectors 
areusedinonetowerandthequery/itemembeddingsaregenerated 
fromtheother.Thatistosay,theaugmentedvectorsa𝑢 
anda𝑣 
summarizethehigh-levelinformationaboutwhataqueryoran 
itempossiblymatchesfromtheothertower.Sincethemimicloss 
istoupdatea𝑢 
anda𝑣 
,weshouldfreezethevalueofp𝑢 
andp𝑣 
.To 
doso,thestopgradientstrategyisappliedtostopthegradientof 
𝑙𝑜𝑠𝑠𝑢 
and𝑙𝑜𝑠𝑠𝑣 
fromflowingbackintop𝑣 
andp𝑢 
. 


Oncethetwoaugmentedvectorsa𝑢 
anda𝑣 
areobtained,they 
areusedtomodeltheinformationinteractionbetweenthetwo 
towersbyregardingthemastheinputfeatureofthetwotowers. 
Finally,theoutputofthemodelistheinnerproductofthequery 
embeddinganditemembedding: 


𝑠 
(u, 
v) 
= 
⟨p𝑢, 
p𝑣⟩ 


where𝑠 
(u, 
v)denotesthescoreprovidedbyourretrievalmodel. 


2.2.3 
CategoryAlignment.Intheindustrialscenario,thecategories 
ofitemswillbediverse(e.g.,food,hotels,movies,etc.)andthe 
numberofitemsineachcategoryisseriouslyuneven.Withthe 
imbalancedcategorydata,thetwo-towermodelperformsdifferentlyforthedifferentcategories,
anditperformsmuchworseon 
thecategorieswithrelativelysmalleramountofitems.Totackle 
theproblem,weproposeaCategoryAlignmentLoss(CAL)for 
trainingphase,whichtransferstheknowledgelearnedinthecategorieswithalargeamountofdatatoothercategories.
Specifically,
foreachbatch,theitemrepresentationp𝑣 
ofthecategory 
withthelargestamountofdataistakentoformthemajorcaten
o 


𝑚𝑎𝑗𝑜𝑟 


goryset:𝑆𝑚𝑎 
𝑗𝑜𝑟 


= 
p 
,andthep𝑣 
ofothercategoriesform 


𝑣 


theirrespectivecategorysets:𝑆2, 
𝑆3, 
𝑆4 
, 
....Wedefinethecategory 
alignmentlossasthedistancebetweenthesecond-orderstatistics 
(covariances)ofthemajorcategoryandothercategoriesfeatures: 


𝑛

Õ 


2

𝑙𝑜𝑠𝑠𝐶𝐴 
= 
C(𝑆𝑚𝑎𝑗𝑜𝑟 
)−C(𝑆𝑖 
) 
(3)

𝐹 
𝑖=2 


where∥·∥2denotesthesquaredmatrixFrobeniusnormand𝑛 
is

𝐹

thenumberofcategories.C(·)representsthecovariancematrix. 


2.3 
ModelTraining 
Wetreattheretrievalproblemasabinaryclassificationproblem,and 
employarandomnegativesamplingframework.Specifically,for 
thequeryineachpositivequery-itempair(label=1),werandomly 
sample𝑆 
itemsfromtheitemcorpustocreate𝑆 
negativequeryitempairs(
label=0)withthisquery,andaddthese𝑆 
+1pairsto 
thetrainingdataset.Thecross-entropylossforthesepairsisas 
follows: 


Õ

1 


𝑙𝑜𝑠𝑠𝑝 
= 
−(𝑦𝑙𝑜𝑔𝜎 
(⟨p𝑢, 
p𝑣⟩)+(1−𝑦)𝑙𝑜𝑔 
(1−𝜎 
(⟨p𝑢, 
p𝑣 
⟩))) 


𝑇 


(𝑢,𝑣,𝑦)∈T 


𝑇 
= 
𝐷 
×(𝑆 
+1) 


(4) 
where𝐷 
isthenumberofpositivefeedbackquery-itempairsand𝑇 
isthetotalnumberoftrainpairs.𝜎 
(·)denotesthesigmoidfunction. 


Thefinallossfunctionisformulatedas: 


𝑙𝑜𝑠𝑠 
= 
𝑙𝑜𝑠𝑠𝑝 
+𝜆1𝑙𝑜𝑠𝑠𝑢 
+𝜆2𝑙𝑜𝑠𝑠𝑣 
+𝜆3𝑙𝑜𝑠𝑠𝐶𝐴 
(5) 


where𝜆1, 
𝜆2, 
𝜆3aretunableparameters. 


DLP-KDD2021,August15,2021,Singapore 


Table1:StatisticsofDatasets. 


Dataset 
#users 
#items 
#interactions 
#categories 


AmazonBooks 
695,513 
243,166 
6,706,125 
11 
Meituan 
82,347,274 
3,561,498 
1,182,652,197 
9 


3 
EXPERIMENTS 


Inthissection,weconductedextensiveonlineandofflineexperimentstojustifytherationalityofDAT’sdesign. 


3.1 
Datasets 
Allmodelswereevaluatedontwoofflinelarge-scaledatasets:a 
largedatasetsampledfromthedailylogsofonlinesystemson 
Meituan1andadatasetfromAmazon[3].TheMeituandataset 
containsdatawithin11consecutivedaysinwhichthedataofthe 
first10dayswasfortrainingandthedataofthe11𝑡ℎ 
daywasfor 
testingandwecombinedalltheitemsthatappearedinthefirst10 
daysastheitemcorpus.TheAmazonBooksisrelativelysmaller, 
andweonlykeptitemsthathavebeenreviewedforleast5times 
anduserswhohavereviewedatleast5items.Weleftthelastitem 
outfortesting.Thedetailsofthetwoofflinedatasetsarelistedin 
Table1. 


3.2 
ExperimentalSetup 
Thefollowingmethodswhichwerewidelyappliedtoindustrial 
wereusedinthecomparisonwiththeproposedDATmodel: 
• 
WALS[1]Amatrixfactorizationalgorithmfordecomposing 
theinteractionmatrixintohiddenfactorsofusersanditems. 


• 
YouTubeDNN[2]Adeepneuralnetworkbasedrecommen


dationapproachthatfedvectorsintoamulti-layerfeedfor


wardneuralnetwork. 


• 
FM[7]Amodelthataccumulatesthefeaturevectorsof 


queryanditemandfeedsthemintotheFMlayer. 


• 
Two-towerModel[4]Apopularmodelinretrievaltaskand 


hasbeenwidelyintroducedtoleveragerichcontentfeature. 


• 
MIND[6]Arecentstate-of-the-artmodelforindustrialre


trievaltask.Thenumberofuserinterestsissetto4and5for 


theMeituandatasetandtheAmazondataset,respectively. 


WeimplementedthesemodelsbydistributedTensorFlowandused 
Faiss[5]toretrievethetop-Nitemsfromthelarge-scaleitempool. 
Theembeddingdimensionandbatchsizewerefixedto32and256 
forallmodels.AllmodelsweretrainedbytheAdamoptimizer. 
Toensureafaircomparison,otherhyperparametersofallmodels 
wereindividuallytunedtoachieveoptimalresults.ForDAT,the 
numberofFClayersineachtowerwasfixedto3,withdimensions 
256,128and32,respectively.Thedimensionsofaugmentedvectors 
a𝑢 
anda𝑣 
werebothsetto𝑑 
= 
32while𝜆1, 
𝜆2weresetto0.5and 
𝜆3wasset1.Toevaluatetheofflineeffectivenessofthevarious 
models,weemployedHitRate@KandMRRmetrics,whichwere 
widelyusedinindustrialretrieval.Kwassetto50and100asthe 
retrievalmodulewasrequiredtoretrievearelativelylargenumber 
ofcandidateitemstofeedtherankingmodule.Duetothelarge 
scaleoftestinginstances,weemployedascaledversionoftheMRR 
byafactorof10. 


1https://www.meituan.com/ 



DLP-KDD2021,August15,2021,Singapore 


Table2:PerformanceComparisonontwodatasetsinterms 
ofHitRateandMRR(w/oisshortforwithout). 


Meituan 
Amazon

Models 


HR@50HR@100 
MRR 
HR@50HR@100 
MRR 


WLAS 
0.2917 
0.4146 
0.3375 
0.0242 
0.0359 
0.0351 
FM 
0.4831 
0.6672 
0.5012 
0.0406 
0.0634 
0.0589 
YouTubeDNN 
0.4228 
0.5142 
0.4512 
0.0378 
0.0599 
0.0524 
Two-tower 
0.5395 
0.7159 
0.5472 
0.0464 
0.0732 
0.0625 
MIND 
0.5507* 
0.7327* 
0.5843* 
0.0490* 
0.0784* 
0.0673* 


DAT 
0.5796 
0.7682 
0.6154 
0.0519 
0.0836 
0.0711 
DAT(w/oCAL) 
0.5655 
0.7512 
0.6009 
0.0503 
0.0816 
0.0698 


3.3 
OfflineResults 
3.3.1 
ModelComparison.TheexperimentalresultsofDATand 
baselinesontwodatasetsarereportedinTable2.Thebestresults 
arelistedinbold,andthebestresultsofbaselinearemarkedwith 
star(*).Clearly,DAToutperformedallbaselinemodelsimproving 
HitRate@100by4.84%and6.63%ontwodatasetsoverthebest 
baseline.ThisdemonstratestheeffectivenessofDATandfurther 
justifiestheimportanceoftheAdaptive-MimicMechanism(AMM) 
andtheCategoryAlignmentLoss(CAL).WALS,thematrixfactorizationapproach,
receivedpoorperformancecomparedwith 
othermethods,confirmingtheeffectivenessofdeeplearningin 
theretrievalstageofrecommendersystems.Theimprovement 
obtainedbyFMcomparedwithYouTubeDNNhighlightstheadvantageoffeatureinteraction.
Moreover,withthehelpofdeep 
learning,thetwo-towermodelperformedmuchbetterthanFM 
andYouTubeDNN,whichcanbeexplainedbythefactthatitcan 
learnqueryanditemrepresentationsfrommorevaluablecontent 
features.Furthermore,consideringthatuserhasmultipleinterests, 
MINDperformsbetterthanthetwo-towermodel.Finally,theadvantageofDAT(
w/oCAL)overMINDandthetwo-towermodel 
andcanbeattributedtotheAMMthatcanexploittheinformation 
interactionbetweenthetwotowers. 
3.3.2 
DimensionofAugmentedVectors.Theaugmentedvectorin 
DATplaysapivotalroleinmodelingthetheinformationinteraction,
toanalyzetheimpactofthedimension,weinvestigatedthe 
performanceofDATonthetwodatasetswithrespecttothedimensionsofaugmentedvectors.
AsFigure2shows,theperformanceof 
DATonMeituanimprovedwiththeincreaseofdimensionwhile 
theperformanceofDATonAmazonimprovedinthefirstplaceand 
thendowngradedsubsequently.Thisiscausedbythedifferencein 
theamountofdatabetweenthetwodatasets.Inaddition,regardless 
ofthedimensionality,itcanalwaysachievebetterperformance, 
whichjustifytheeffectivenessoftheaugmentedvector. 
3.4 
OnlineExperiments 
Inadditiontoofflinestudies,weconductedonlineexperimentsby 
deployingDATtohandletherealtrafficforoneweekinarecommendersystemwhichserves60millionusersperday.
Tomake 
afaircomparison,theretrievalstagewasfollowedbythesame 
rankingprocedure.CTRandGMV,twowidelyusedindustrialmetrics,
wereusedtomeasuretheperformanceofmodelsforserving 
onlinetraffic.Thebaselinemethodforonlineexperimentswasthe 
two-towermodel,whichwasthebaseretrievalalgorithmserving 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 



Figure2:PerformanceintermsofHR@100andMRRw.r.t 
thedimensionsofaugmentedvectorsonthetwodatasets. 



Figure3:OnlineperformanceofDATandbaselines 


themajorityoftheonlinetraffic.Therewereonehundredcandidateitemsretrievedbyeachmethodandfedtotherankingstage. 
Figure3showstheonlineresultsin7successivedays.Ourmodel 
outperformedthebaselinewithalargemargin,withanoverall 
averageimprovementsof4.17%and3.46%intermsofCTRand 
GMV,respectively. 


4 
CONCLUSION 


Inthispaper,wepresentaneffectiveretrievalmodelnamedDual 
AugmentedTwo-towerModel(DAT)forindustrialrecommendation 
systems.Itaimstomodeltheinformationinteractionbetweenthe 
twotowersandproducesbetteritemrepresentationsforimbalanced 
categorydata.Extensiveexperimentsonofflineandonlinedatasets 
showthattheDATmodel,withAMMandCAL,caneffectively 
achievesuperiorperformance. 


REFERENCES 


[1]ChristopherRAberger.2014.Recommender:Ananalysisofcollaborativefiltering 
techniques.PersonalandUbiquitousComputingJournal(2014). 


[2]PaulCovington,JayAdams,andEmreSargin.2016.Deepneuralnetworksfor 
youtuberecommendations.InProceedingsofthe10thACMconferenceonrecommendersystems.
191–198. 


[3]RuiningHeandJulianMcAuley.2016.Upsanddowns:Modelingthevisual 
evolutionoffashiontrendswithone-classcollaborativefiltering.Inproceedingsof 
the25thinternationalconferenceonworldwideweb.507–517. 
[4]Po-SenHuang,XiaodongHe,JianfengGao,LiDeng,AlexAcero,andLarryHeck. 
2013.Learningdeepstructuredsemanticmodelsforwebsearchusingclickthrough 
data.InProceedingsofthe22ndACMinternationalconferenceonInformation& 
KnowledgeManagement.2333–2338. 


[5]JeffJohnson,MatthijsDouze,andHervéJégou.2017.Billion-scalesimilaritysearch 
withGPUs.arXivpreprintarXiv:1702.08734(2017). 


[6]ChaoLi,ZhiyuanLiu,MengmengWu,YuchiXu,HuanZhao,PipeiHuang,GuoliangKang,
QiweiChen,WeiLi,andDikLunLee.2019.Multi-interestnetwork 
withdynamicroutingforrecommendationatTmall.InProceedingsofthe28thACM 
InternationalConferenceonInformationandKnowledgeManagement.2615–2623. 


[7]SteffenRendle.2010.FactorizationMachines.InICDM2010,The10thIEEEInternationalConferenceonDataMining,
Sydney,Australia,14-17December2010. 



